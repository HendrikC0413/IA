{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ff0565-a98d-47d3-8438-08f733e16088",
   "metadata": {},
   "source": [
    "#### Parte 3: Arquitectura de una CNN\n",
    "\n",
    "Una arquitectura típica de CNN consiste en capas alternadas de convolución y pooling, seguidas de capas completamente conectadas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51424f0-9f16-4825-8830-8b648ee4eaa5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Una capa convolucional con 32 filtros, tamaño de kernel 3x3 y activación ReLU.\n",
    "- Una capa de max pooling con tamaño de pool 2x2.\n",
    "- Una segunda capa convolucional con 64 filtros, tamaño de kernel 3x3 y activación ReLU.\n",
    "- Una segunda capa de max pooling con tamaño de pool 2x2.\n",
    "- Una tercera capa convolucional con 64 filtros, tamaño de kernel 3x3 y activación ReLU.\n",
    "- Una capa completamente conectada con 64 unidades y activación ReLU.\n",
    "- Una capa de salida con 10 unidades y activación softmax (para una clasificación de 10 clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08b434-2b0f-4ca8-b176-0f944c995633",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explicación\n",
    "\n",
    "1. **Capas Convolucionales**:\n",
    "   - `self.conv1`: 32 filtros, tamaño de kernel 3x3, activación ReLU.\n",
    "   - `self.conv2`: 64 filtros, tamaño de kernel 3x3, activación ReLU.\n",
    "   - `self.conv3`: 64 filtros, tamaño de kernel 3x3, activación ReLU.\n",
    "\n",
    "2. **Capas de Pooling**:\n",
    "   - `self.pool1`: Max pooling con tamaño 2x2.\n",
    "   - `self.pool2`: Max pooling con tamaño 2x2.\n",
    "   - `self.pool3`: Max pooling con tamaño 2x2.\n",
    "\n",
    "3. **Capas Completamente Conectadas**:\n",
    "   - `self.fc1`: 64 unidades, activación ReLU.\n",
    "   - `self.fc2`: 10 unidades (para 10 clases de salida).\n",
    "\n",
    "4. **Aplanado**:\n",
    "   - `x = x.view(-1, 64 * 4 * 4)`: Aplanar las características antes de pasar a las capas completamente conectadas.\n",
    "\n",
    "### Uso del Modelo\n",
    "\n",
    "Para usar este modelo, puedes definir un conjunto de datos, un optimizador y un criterio de pérdida, y luego entrenar la red con tus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be08db9c-0575-4ee6-b5aa-2c5e3118931c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Capa convolucional 1: 32 filtros, kernel 3x3, activación ReLU\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        # Capa de max pooling 1: tamaño del pool 2x2\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Capa convolucional 2: 64 filtros, kernel 3x3, activación ReLU\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        # Capa de max pooling 2: tamaño del pool 2x2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Capa convolucional 3: 64 filtros, kernel 3x3, activación ReLU\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # Capa de max pooling 3: tamaño del pool 2x2\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Capa completamente conectada: 64 unidades, activación ReLU\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        # Capa de salida: 10 unidades (para clasificación en 10 clases), activación softmax\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aplicar la primera capa convolucional seguida de ReLU y pooling\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        # Aplicar la segunda capa convolucional seguida de ReLU y pooling\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # Aplicar la tercera capa convolucional seguida de ReLU y pooling\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        # Aplanar las características para la capa completamente conectada\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # Aplicar la primera capa completamente conectada seguida de ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Aplicar la capa de salida\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Crear una instancia de la red\n",
    "net = CNN()\n",
    "\n",
    "# Mostrar la arquitectura del modelo\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61910d-4cb4-4c1e-b146-f5a2dad9eeac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Descarga del modelo CIFAR-10\r\n",
    "**Transformaciones para los datos de entrada**\r\n",
    "Se define una serie de transformaciones que se aplicarán a las imágenes del conjunto de datos. En este caso, se convierte la imagen a un tensor y se normalizan los valores de los píxeles.\r\n",
    "\r\n",
    "**Cargando el conjunto de entrenamiento**\r\n",
    "Se descarga y carga el conjunto de datos CIFAR-10 para entrenamiento. Este conjunto contiene imágenes etiquetadas que se utilizarán para entrenar un modelo. Las imágenes se transforman según lo definido anteriormente.\r\n",
    "\r\n",
    "**Cargando el conjunto de prueba**\r\n",
    "Similar al conjunto de entrenamiento, se descarga y carga el conjunto de datos CIFAR-10 para pruebas. Este conjunto se utiliza para evaluar el rendimiento del modelo entrenado. Las imágenes también se transforman de la misma manera.\r\n",
    "\r\n",
    "**Clases en CIFAR-10**\r\n",
    "Se define una lista de las diez clases de objetos que están presentes en el conjunto de datos CIFAR-10, como aviones, automóviles, pájaros, gatos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d755d35-d52a-4425-a76a-729e254d4f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transformaciones para los datos de entrada\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # Normalización para CIFAR-10\n",
    "\n",
    "# Cargando el conjunto de entrenamiento\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Cargando el conjunto de prueba\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Clases en CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e5af9-457b-499f-a2f2-b96cc6ce2a05",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "**Función de pérdida y optimizador**\r\n",
    "Se define la función que mide la discrepancia entre las predicciones del modelo y las etiquetas reales (en este caso, se usa la pérdida de entropía cruzada). También se define el optimizador, que ajusta los parámetros del modelo durante el entrenamiento para reducir la pérdida, utilizando el método de Gradiente Estocástico (SGD) con una tasa de aprendizaje y momento específicos.\r\n",
    "\r\n",
    "**Ciclo de entrenamiento**\r\n",
    "Se itera sobre el conjunto de datos varias veces (epochs). Para cada epoch:\r\n",
    "- Se inicializa la pérdida acumulada.\r\n",
    "- Se itera sobre los datos del conjunto de entrenamiento en lotes pequeños (mini-batches).\r\n",
    "- Para cada lote:\r\n",
    "  - Se obtienen las entradas y las etiquetas.\r\n",
    "  - Se ponen a cero los gradientes de los parámetros del modelo.\r\n",
    "  - Se calculan las predicciones del modelo y la pérdida.\r\n",
    "  - Se realiza la retropropagación de la pérdida para calcular los gradientes.\r\n",
    "  - Se actualizan los parámetros del modelo con el optimizador.\r\n",
    "- Cada 2000 mini-batches, se imprime la pérdida media acumulada.\r\n",
    "\r\n",
    "**Finalización del entrenamiento**\r\n",
    "Se indica que el entrenamiento ha terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53a1b1b-cb51-4355-9064-7ed5cf104d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.151\n",
      "[1,  4000] loss: 1.771\n",
      "[1,  6000] loss: 1.560\n",
      "[1,  8000] loss: 1.442\n",
      "[1, 10000] loss: 1.338\n",
      "[1, 12000] loss: 1.268\n",
      "[2,  2000] loss: 1.158\n",
      "[2,  4000] loss: 1.104\n",
      "[2,  6000] loss: 1.059\n",
      "[2,  8000] loss: 1.044\n",
      "[2, 10000] loss: 0.990\n",
      "[2, 12000] loss: 0.958\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9879c8-6568-4074-bff2-7d7da5759130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
